<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection">
  <meta name="keywords" content="Reinforcement Learning, Robotics, Perception, Inspection">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic
            Inspection</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="#">Richard Kuhlmann</a><sup>1, *</sup>,</span>
            <span class="author-block">
              <a href="#">Jakob Wolfram</a><sup>1, *</sup>,</span>
            <span class="author-block">
              <a href="https://boysun045.github.io/boysun-website/">Boyang Sun</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://jiaxux.ing/">Jiaxu Xing</a><sup>3</sup>,
            </span>

	<br> <!-- separate line -->
            <span class="author-block">
              <a href="https://rpg.ifi.uzh.ch/people_scaramuzza.html">Davide Scaramuzza</a><sup>3</sup>
            </span>
            <span class="author-block">
              <a href="https://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a><sup>2, 4</sup>
            </span>
            <span class="author-block">
              <a href="https://n.ethz.ch/~cesarc/">Cesar Cadena</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution,</span>
	<br> <!-- separate line -->
            <span class="author-block"><sup>1</sup>Robotic Systems Lab, ETH Zurich,</span>
            <span class="author-block"><sup>2</sup>Computer Vision and Geometry Group, ETH Zurich</span>
            <span class="author-block"><sup>3</sup>Robotics and Perception Group, University of Zurich</span>
            <span class="author-block"><sup>4</sup>Microsoft</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block"> -->
              <!--   <a href="#" -->
              <!--      class="external-link button is-normal is-rounded is-dark"> -->
              <!--     <span class="icon"> -->
              <!--         <i class="fas fa-file-pdf"></i> -->
              <!--     </span> -->
              <!--     <span>Paper</span> -->
              <!--   </a> -->
              <!-- </span> -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video (coming soon!)</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon!)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block"> -->
              <!--   <a href="#" -->
              <!--      class="external-link button is-normal is-rounded is-dark"> -->
              <!--     <span class="icon"> -->
              <!--         <i class="far fa-images"></i> -->
              <!--     </span> -->
              <!--     <span>Data</span> -->
              <!--     </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="content has-text-centered">
        <h2 class="subtitle">
          <span class="dnerf">Sight Over Site</span> presents a novel approach to perception-aware reinforcement learning for efficient robotic inspection tasks.
        </h2>
        <!-- <p class="content"> -->
        <!--   Coming soon: Demonstrations and visualization of our perception-aware robotic inspection methodology. -->
        <!-- </p> -->
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Autonomous inspection is a central problem in
            robotics, with applications ranging from industrial monitoring
            to search-and-rescue. Traditionally, inspection has often been
            reduced to navigation tasks, where the objective is to reach
            a predefined location while avoiding obstacles. However, this
            formulation captures only part of the real inspection problem.
            In real-world environments, the inspection targets may become
            visible well before their exact coordinates are reached, making
            further movement both redundant and inefficient. 
          </p>
          <p>
            What matters more for inspection is not simply arriving at the targetâ€™s
            position, but positioning the robot at a viewpoint from which the
            target becomes observable. In this work, we revisit inspection
            from a perception-aware perspective. We propose an end-to-end
            reinforcement learning framework that explicitly incorporates
            target visibility as the primary objective, enabling the robot
            to find the shortest trajectory that guarantees visual contact
            with the target without relying on a map. The learned policy
            leverages both perceptual and proprioceptive sensing and is
            trained entirely in simulation, before being deployed to a real-
            world robot. We further develop an algorithm to compute
            ground-truth shortest inspection paths, which provides a ref-
            erence for evaluation. Through extensive experiments, we show
            that our method outperforms existing classical and learning-
            based navigation approaches, yielding more efficient inspection
            trajectories in both simulated and real-world settings.
          </p>
        </div>
      </div>
    </div>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Method</h2>
        <img src="./static/images/teaser-figure.png" alt="Method" style="max-width: 80%; height: auto;">
        <h2 class="subtitle has-text-centered" style="font-size: 15px;">
	To obtain visual access to a given target, the inspection policy (green path) results in a shorter trajectory compared to the navigation policy (red path). Our proposed RL-based policy (bottom right) takes egocentric depth input along with the target and robot state to achieve efficient inspection.
        </h2>
    </div>
  </div>
</section>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <p>Video demonstration coming soon.</p>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Methodology. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Methodology</h2>
          <p>
            Stay tuned, coming soon!
          </p>
        </div>
      </div>
      <!--/ Methodology. -->

      <!-- Results. -->
      <div class="column">
        <h2 class="title is-3">Results</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Stay tuned, coming soon. Spoiler: We are efficient! 
            </p>
          </div>

        </div>
      </div>
    </div>
    <!--/ Results. -->

    <!-- Future Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Future Directions</h2>

        <div class="content has-text-justified">
          <p>
            Future work will explore extensions to non-planar movement and 3D dynamics.
          </p>
        </div>

      </div>
    </div>
    <!--/ Future Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{sightoversite2025,
  author    = {Kuhlmann, Richard and Wolfram, Jakob and Sun, Boyang and Xing, Jiaxu and Scaramuzza, Davide and Pollefeys, Marc and Cadena, Cesar},
  title = {Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection},
  journal   = {ArXiv},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="#" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            We thank the original authors for making their website template available.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
